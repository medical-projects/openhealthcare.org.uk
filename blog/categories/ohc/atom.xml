<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ohc | Open Health Care UK - Blog]]></title>
  <link href="http://openhealthcare.org.uk/blog/categories/ohc/atom.xml" rel="self"/>
  <link href="http://openhealthcare.org.uk/"/>
  <updated>2016-11-04T14:58:58+00:00</updated>
  <id>http://openhealthcare.org.uk/</id>
  <author>
    <name><![CDATA[Open Health Care UK]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Big Problems in Health Tech That Get Us Excited]]></title>
    <link href="http://openhealthcare.org.uk/blog/2016/06/06/big-problems-in-health-tech-that-get-us-excited/"/>
    <updated>2016-06-06T12:59:20+01:00</updated>
    <id>http://openhealthcare.org.uk/blog/2016/06/06/big-problems-in-health-tech-that-get-us-excited</id>
    <content type="html"><![CDATA[One of the great things about working in health is that there are no shortage of exciting, and potentially impactful problems to
work on. At Open Health Care, we spend a lot of our time working to ease a couple of the big headaches around usability and
data that the current state of health care technology gives clinicians.

## Usability

First is the usability problem.

We’re hardly the first people to suggest that many, if not most of the digital tools that are provided for doctors, nurses and
other key front line NHS staff struggle with usability. By default these tools tend to be overwhelming and unfriendly. They are
hard to use, and at times downright dangerous.

At Open Health Care we believe that medicine is important enough to deserve the very best in terms of high quality usable software.
In an environment where the costs of making mistakes is so high, clinicians deserve tools that help rather than hinder.

The great thing is that technologists understand how to make tools that are highly functional and even delight their users. It
requires time, focus and a willingness to change the way things are done - but the
[design](http://thisisservicedesignthinking.com/)
[and](http://www.usability.gov/what-and-why/user-centered-design.html)
[development](http://www.agilemanifesto.org/)
[techniques](https://www.gov.uk/service-manual) are
increasingly widespread and available to us.

There is no reason why we can’t do this for medicine - and indeed, the biggest part of what we do as Open Health Care is
[delivering that](http://openhealthcare.org.uk/blog/2016/02/16/how-were-helping-respond-to-the-zika-outbreak/).

In the UK, our reality is that we are looking to streamline and improve the efficiency of our clinical services in the name of yes,
better care but also saving the NHS money. Having usable digital tools that genuinely support the day to day work of those services
with the capability to be frequently iterated will be a key plank of any successful transformation strategy as we look to re-design
those services.

## Data

The second big area that gets us excited is clinical data.

If we get sick, then the people and institutions who care for us know a huge amount about us. But that information is rarely
available as data. It’s either literally on paper notes, or it’s in electronic systems that may as well be paper - stored in closed
systems in unstructured formats that we can’t subsequently analyse or do computations over.

The opportunity cost of throwing away this information is huge. The truly revolutionary technologies and techniques that the
digital age has provided us are fuelled by data. Those techniques work best when you can feed them with structured, high
quality, granular data. Yet even at many world-renowned institutions in the NHS, the data infrastructure underpinning clinical
activity is distinctly 20th century.

Access to high quality clinical data by default has a transformative potential for the NHS. Improving patient care and optimising
our clinical services requires a real understanding of what we’re doing now - and that can only be obtained with data. Without that
data, we have no idea whether we’re even making things better.

And that’s before we even start with the promise of driving research and science by providing them with easily accessible, high
quality, computable clinical data.

## How do we help?

What we’ve found at Open Health Care, is that when you
[get the usability right](http://openhealthcare.org.uk/blog/2015/03/11/how-doctors-get-digital-services-they-love/)
for the end user - the person caring for a patient,
you can improve the efficiency and safety of patient care, while also capturing high granularity, research quality data as a part
of routine clinical care.

This is one of the reasons we created
[OPAL](https://github.com/openhealthcare/opal) - our Open Source platform for building clinical software applications. It pulls together
the results of years of usability testing with real clinicians, along with all of the hard thinking that we and others like us have
done about how to build robust digital tools for a health care environment.

Also built in to
[OPAL](opal.openhealthcare.org.uk/docs/v0.6.0/)
is the ability and the data modelling to collect the granularity of data required to enable us to provide
high quality data through extracts or Open APIs. We’ve explored how to balance the clinical user need of speed ease of use with
the system needs of quality data capture. Through a combination of pragmatic design, and frequent iteration, we’ve arrived at a
range of design patterns that give us the opportunity to design systems that work in the real world yet still enable subsequent
analysis.

For instance, we’ve built
[elCID](http://elcid.openhealthcare.org.uk/) - the first major application built using OPAL. It’s designed to help manage the care of
patients with infections, and it has been in use at
[University College Hospital London](https://www.uclh.nhs.uk/Pages/Home.aspx) for the last two and a half years in the
inpatient and outpatient services they run for patients with infections. It is used by clinicians day to day to manage the care of
patients, integrating with other hospital systems to pull key data from elsewhere in the trust, and it supports both clinical audit
and service development.

During that time it has improved the efficiency of clinical practice - saving time every single day by reducing work required in
the handover process for inpatient teams, and reducing significantly, the time required by Microbiology consultants to run their
liaison service to other parts of the trust - while providing robust documentation of that process for the first time.

It has supported the development of the
[OPAT service](http://openhealthcare.org.uk/blog/2015/02/05/elcid-opat-launch/)
- freeing up beds by allowing patients requiring IV antibiotics to be treated
as outpatients, saving the trust £1m per year. It also allows us to provide clinic managers realtime dashboards and management
reports about their activity, enabling them to make decisions with data that was previously unavailable to them.

In addition to this, data from the system has supported many clinical audits - making the process of collecting data to analyse
significantly faster, as well as
[one published academic paper](http://openhealthcare.org.uk/blog/2015/06/10/elcid-journal-of-infectioncontrol/),
two more in peer review, and six conference abstracts.

## How does it work?

Open Health Care provide digital tools to NHS institutions that help clinicians to deliver better care. We charge for support,
customisation and integration work, but we don’t charge for a license fee - all of our software is Open Source.

We provide either installations of existing products we have developed, or build bespoke solutions for the needs of the individual
organization we’re working with.

If you are interested in fining out how to get elCID at your organization, or have a project that involves clinical usability and
data then do [drop us a line](mailto:hello@openhealthcare.org.uk) - we’d love to hear from you.
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How We Manage Risk When We Use Open Source in Health]]></title>
    <link href="http://openhealthcare.org.uk/blog/2016/04/06/how-we-manage-risk-when-we-use-open-source-in-health/"/>
    <updated>2016-04-06T09:00:29+01:00</updated>
    <id>http://openhealthcare.org.uk/blog/2016/04/06/how-we-manage-risk-when-we-use-open-source-in-health</id>
    <content type="html"><![CDATA[In the last couple weeks, many thousands of words have been written about a small piece of open source code called left-pad which was suddenly un-published by its author. (If you’re not up to speed on this, then you might like to
read a [narrative overview](http://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/), or
[some](http://www.haneycodes.net/npm-left-pad-have-we-forgotten-how-to-program/)
[interesting](http://lucumr.pocoo.org/2016/3/24/open-source-trust-scaling/)
[analysis](http://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm).)

Perfectly understandably, this has caused lots of people to re-consider the risks of building on open source, and how the actions of unaccountable external developers halfway around the world could have an effect on how your software operates.

When we work with digital tools for health, risk can be particularly profound. The failure mode of a digital service that supports clinicians delivering direct care is the risk of IT failures causing harm to patients, not just a website being unavailable for a while. This means that we need to make sure that our attitude to risk is appropriate to the harm that failures can cause.

Thankfully, there are plenty of people using open source, and lots of them using it for mission critical applications that have exacting uptime expectations. That means that the path to processes and tools to mitigate these risks is well trodden, and we can learn from the wealth of cultural knowledge in the open source movement.

Taking a straw poll of the table I'm sat at, there are people who've written code using open source for investment banks, power stations, government departments, and yes, NHS hospitals.

The story of how all those places avoid their production systems being broken by code that has been altered by unknown open source developers is basically identical.

### Software Dependencies at Open Health Care


<div class="post-thumb">
  <img class="img-responsive" src="http://openhealthcare.org.uk/assets/images/people/david.ross.jpg" alt="" />
</div><!--//post-thumb-->


A <a href="https://en.wikipedia.org/wiki/Coupling_(computer_programming)">dependency</a> is a
broad software engineering term used to explain the relationship when a piece of software relies
on another one. When programmers install and run software from other sources, they will most often use a
[package manager](https://en.wikipedia.org/wiki/Package_manager) - software that automates the
process of installing and upgrading code.

Before we install a new package or module of open source code, we carefully evaluate it. We look at the code, we look at its user base, we look at how actively maintained it is by the open source community and we look at the risk that it presents to the rest of our code base. The decision has to be signed off by at least two people in our development team, and it’s not one we take lightly. (Explaining how this review and evaluation process works in detail is probably a whole post in itself.)

Once we’ve taken that decision, we have to update our code to incorporate the new dependency.
[Every](https://pypi.python.org/pypi/)
[major](https://www.npmjs.com/)
[open](https://hex.pm/)
[source](https://rubygems.org/)
[package](http://www.cpan.org/)
[manager](https://help.ubuntu.com/lts/serverguide/package-management.html) includes the concept of
[software versions](https://en.wikipedia.org/wiki/Software_versioning). When we use external code, we &#8220;pin&#8221; that code to
[a particular version](https://github.com/openhealthcare/elcid/blob/v0.6.0/requirements.txt). The exact mechanism we use to do that varies, but always means that we end up explicitly defining the exact version number of a piece of code in our application.

That means that every time we re-install, we get the exact same software.
Our [automated test suites](https://travis-ci.org/openhealthcare/) are run against the exact same software. When we deploy to a staging environment to do testing and quality control, it&#8217;s the exact same software. When we deploy to production&#8230; you get the picture I&#8217;m sure.

If the author of that code releases a new version, we’ll hear about it from the project mailing list, or from blog posts about it, but that code doesn’t automatically find its way into our applications.

When we decide to upgrade a dependency that&#8217;s a task that&#8217;s
[assigned to a programmer](https://waffle.io/openhealthcare/opal-ideas) as part of a
<a href="https://en.wikipedia.org/wiki/Scrum_(software_development)#Sprint">sprint</a>. That task
will consist of a number of things:

* They have to review the changes to the library.
* They have to change several pieces of configuration management code.
* They have to run all of our automated test suites and make sure they pass.
* They have to get the upgrade accepted by a [peer review process](https://help.github.com/articles/using-pull-requests/) (another programmer has to OK the decision).

And that&#8217;s just to change the latest version for a fresh install. It is nowhere near production yet. To get there you have full change approval and acceptance testing processes that are in place for
individual deployments.

### So how did left-pad affect us?

The short answer is, it didn’t.

By the time the applications we support are deployed, they safely include all of the code that’s required to run them, and that code is carefully managed.

The real disruption caused by left-pad was to the working life of programmers. It would have meant that new installations failed, or
perhaps [automated test suites](https://en.wikipedia.org/wiki/Continuous_integration) didn&#8217;t pass. If we’d been working at 22:30 PM last tuesday, then during the two and a half hours that the whole affair lasted, it might have made us a little less productive. If we’d been doing a planned upgrade or deployment of one of our applications, we might have had to postpone it. (Although we likely would have been just fine with the specific left-pad issues.)

What it has meant, is that we’ve taken the opportunity to review our processes to make sure that we’re following established best practices for open source development in domains where managing risk is as important as health. And we welcome that opportunity - we’re always striving to make sure that our engineering standards are as high as possible.

### Open Source or just good software engineering?

One of the great things about the open source movement is that we’re able to have high quality conversations about things like risk and failure in the open. When things go wrong, we’re happy to talk about it. The open movement shares its knowledge from the tough times as well as the good times. The open movement means that the stakeholder involvement and the responsibility is shared. If a solution needs to be found, it can often be found quicker and to a higher standard because it is being required and reviewed by such a large body of individuals.

More broadly, every software vendor, produces applications that depend on code they haven’t written themselves - regardless of licensing. Managing dependencies is a part of all modern software engineering. The most important factor here is not the licence under which that code exists. What does matter, is having an approach to risk that’s appropriate and responsible.

If you’d like to know more about the processes we use to make sure that we deliver the highest quality service to the clinical teams who use our products,
or if you’d like to know more about how we might be able to help you, then do <a href="mailto:hello@openhealthcare.org.uk">get in touch</a>.

<small>
Photo credits: [Paul Clarke](flickr.com/photos/paul_clarke/)
</small>
]]></content>
  </entry>
  
</feed>
